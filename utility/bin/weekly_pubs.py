''' weekly_pubs.py
    Run all the librarian's scripts for the weekly pipeline, in order.
    This script should live in utility/bin. It expects update_dois.py to be in sync/bin.
    I'm keeping the --write flag for consistency with all our other scripts, 
    but it doesn't really make sense to NOT include the --write flag in this script.
    New DOIs won't be added to the database, so the downstream scripts won't work.

    Because this script contains a couple of checks on the validity of the DOIs,
    the librarian should always run THIS script to add DOIs to the database, 
    and they should NOT run update_dois.py directly.
'''

import os
import sys
import argparse
import requests
import copy
import subprocess
from collections.abc import Iterable
import jrc_common.jrc_common as JRC
import doi_common.doi_common as doi_common
from operator import attrgetter
from termcolor import colored



# Functions to pass command line args to subsequent python scripts

def create_command(script, ARG): # will produce a list like, e.g. ['python3', 'update_dois.py', '--doi' '10.1038/s41593-024-01738-9', '--verbose']
    return(
        list(flatten( ['python3', script, doi_source(ARG), verbose(ARG), write(ARG)] ))
    )

def doi_source(ARG):
    if ARG.DOI:
        return( ['--doi', ARG.DOI] )
    elif ARG.FILE:
        return(['--file', ARG.FILE])

def verbose(ARG):
    if ARG.VERBOSE:
        return('--verbose')
    else:
        return([])

def write(ARG):
    if ARG.WRITE:
        return('--write')
    else:
        return([])

def flatten(xs): # https://stackoverflow.com/questions/2158395/flatten-an-irregular-arbitrarily-nested-list-of-lists
    for x in xs:
        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):
            yield from flatten(x)
        else:
            yield x



# Functions to handle DOIs already in the database

def copy_arg_for_sync(ARG):
    arg_copy = copy.deepcopy(ARG)
    dois = get_dois_from_user_input(ARG) # a list
    dois_to_sync = [ d for d in dois if not already_in_dis_db(d) ]
    if ARG.DOI:
        if dois_to_sync:
            arg_copy.DOI = next(flatten(dois_to_sync)) # unlist to produce a string
        else:
            arg_copy.DOI = []
    elif ARG.FILE:
        with open('to_sync.txt', 'w') as outF:
            outF.write("\n".join(dois_to_sync) )
        arg_copy.FILE = 'to_sync.txt'
    return(arg_copy)

def get_dois_from_user_input(ARG):
    dois = [ARG.DOI.lower()] if ARG.DOI else [] # .lower() because our collection is case-sensitive
    if ARG.FILE:
        try:
            with open(ARG.FILE, "r", encoding="ascii") as instream:
                for doi in instream.read().splitlines():
                    dois.append(doi.strip().lower())
        except Exception as err:
            print(f"Could not process {ARG.FILE}")
            exit()
    return(dois)


# Functions to check whether any DOIs can't be added to the DB because the crossref metadata aren't available yet.
# As far as I can tell, biorxiv is the only publisher that ever publishes a DOI before the DOI is in crossref.
# Checking for the DOI in biorxiv ensures it's a real DOI, not just a typo.

def handle_dois_in_biorxiv_but_not_crossref(ARG):
    dois = get_dois_from_user_input(ARG)
    for doi in dois:
        if not in_crossref(doi):
            if in_biorxiv(doi):
                if ARG.WRITE:
                    doi_common.add_doi_to_process(doi, dois_to_process_collection)
                    print(colored(
                        (f'WARNING: {doi} is in bioRxiv but not Crossref. Added to dois_to_process_collection. Will be added to DIS DB automatically as soon as possible.'), "yellow"
                    ))
            else:
                print(colored(
                    (f'WARNING: {doi} is not in Crossref or bioRxiv. Might it contain a typo?'), "yellow"
                ))


def in_biorxiv(doi):
    if JRC.call_biorxiv(doi)['messages'][0]['status'] == 'ok':
        return(True)
    else:
        return(False)

def in_crossref(doi):
    if JRC.call_crossref(doi):
        return(True)
    else:
        return(False)




# Functions to query the API

def already_in_dis_db(doi):
    if get_rest_info(doi)["source"] == "mongo":
        return(True)
    else:
        return(False)

def get_rest_info(doi):
    rest = JRC.get_config("rest_services")
    url_base = attrgetter("dis.url")(rest)
    url = f'{url_base}doi/{replace_slashes_in_doi(strip_doi_if_provided_as_url(doi))}'
    response = get_request(url)
    return( response['rest'] ) 

def replace_slashes_in_doi(doi):
    return( doi.replace("/", "%2F") ) # e.g. 10.1186/s12859-024-05732-7 becomes 10.1186%2Fs12859-024-05732-7

def strip_doi_if_provided_as_url(doi, substring=".org/10.", doi_index_in_substring = 5):
    # Find all occurrences of the substring
    occurrences = [i for i in range(len(doi)) if doi.startswith(substring, i)]
    if len(occurrences) > 1:
        print("Warning: Please check that your DOI is formatted correctly.")
        exit(1)  # Exit with a warning code
    elif len(occurrences) == 1:
        doi_index_in_string = occurrences[0]
        stripped_doi = doi[doi_index_in_string + doi_index_in_substring:]
        return(stripped_doi)
    else:
        return(doi)

def get_request(url):
    headers = { 'Content-Type': 'application/json' }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return(response.json())
    else:
        print(f"There was an error with the API GET request. Status code: {response.status_code}.\n Error message: {response.reason}")
        sys.exit(1)



# Functions and variables to connect to DIS DB

DB = {}
PROJECT = {}

def initialize_program():
    ''' Intialize the program
        Keyword arguments:
          None
        Returns:
          None
    '''
    # Database
    try:
        dbconfig = JRC.get_config("databases")
    except Exception as err:
        terminate_program(err)
    dbs = ['dis']
    for source in dbs:
        manifold = 'prod'
        dbo = attrgetter(f"{source}.{manifold}.write")(dbconfig)
        try:
            DB[source] = JRC.connect_database(dbo)
        except Exception as err:
            terminate_program(err)
    try:
        rows = DB['dis'].project_map.find({})
    except Exception as err:
        terminate_program(err)
    for row in rows:
        PROJECT[row['name']] = row['project']

def terminate_program(msg=None):
    ''' Terminate the program gracefully
        Keyword arguments:
          msg: error message
        Returns:
          None
    '''
    if msg:
        if not isinstance(msg, str):
            msg = f"An exception of type {type(msg).__name__} occurred. Arguments:\n{msg.args}"
            LOGGER.critical(msg)
            sys.exit(-1 if msg else 0)


# -----------------------------------------------------------------------------

if __name__ == '__main__':

    PARSER = argparse.ArgumentParser(
    description = "Run the weekly pipeline for one or more DOIs: add DOI(s) to database, curate authors and tags, and print citation(s).")
    MUEXGROUP = PARSER.add_mutually_exclusive_group(required=True)
    MUEXGROUP.add_argument('--doi', dest='DOI', action='store',
                            help='Single DOI to process')
    MUEXGROUP.add_argument('--file', dest='FILE', action='store',
                            help='File of DOIs to process')
    PARSER.add_argument('--sync_only', dest='SYNC_ONLY', action='store_true',
                        default=False, help='Flag, simply add DOI(s) to database without running downstream scripts.')
    PARSER.add_argument('--verbose', dest='VERBOSE', action='store_true',
                        default=False, help='Flag, Chatty')
    PARSER.add_argument('--debug', dest='DEBUG', action='store_true',
                        default=False, help='Flag, Very chatty')
    PARSER.add_argument('--write', dest='WRITE', action='store_true',
                        default=False, help='Write results to database. If --write is missing, no changes to the database will be made.')

    ARG = PARSER.parse_args()
    LOGGER = JRC.setup_logging(ARG)
    # Connect to the database
    initialize_program()
    dois_to_process_collection = DB['dis'].dois_to_process

# We don't want to add a DOI to the database that is already in there. (The load source will be set to 'Manual' in the metadata, which is misleading.)
# We can use the API to check whether the DOI is already in the database.
    arg_copy = copy_arg_for_sync(ARG) # create a copy of ARG.DOI or ARG.FILE that contains only the DOIs that are not already in the DB.
    # Because my create_command function is expecting an ARG object, this was easier than creating a new data structure.
    if not arg_copy.DOI and not arg_copy.FILE:
        print(colored(
                ("WARNING: No DOIs to add to database. Skipping sync."), "yellow"
            ))
    else:
        handle_dois_in_biorxiv_but_not_crossref(arg_copy) # Warn the user about any DOIs that aren't in Crossref.
        # If the DOI is in bioRxiv but not Crossref, the DOI is added to the dois_to_process collection.
        sync_bin_path = os.path.normpath(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'sync', 'bin'))
        subprocess.call(create_command(f'{sync_bin_path}/update_dois.py', arg_copy))
    
    if not ARG.SYNC_ONLY:
        subprocess.call(create_command('name_match.py', ARG))
        subprocess.call(create_command('update_tags.py', ARG))
        subprocess.call(list(flatten( ['python3', 'get_citation.py', doi_source(ARG)] ))) 

